{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit1_Sprint3_Challenge_Samuel_Egbert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel-Egbert31415/DS-Unit-1-Sprint-1-Data-Wrangling-and-Storytelling/blob/master/Unit1_Sprint3_Challenge_Samuel_Egbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elas4Ibsv5Ni"
      },
      "source": [
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* **Download this notebook** as you would any other ipynb file\n",
        "* **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "* **Delete `raise NotImplementedError()`**\n",
        "* Write your code in the `# YOUR CODE HERE` space\n",
        "* **Execute** the Test cells that contain `assert` statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "* **Save** your notebook when you are finished\n",
        "* **Download** as a `ipynb` file (if working in Colab)\n",
        "* **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQxE7E4O2Yx"
      },
      "source": [
        "# Lambda School Data Science - Unit 1 Sprint 3\n",
        "\n",
        "## Sprint Challenge - Linear Algebra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D90eph5lO5dp"
      },
      "source": [
        "## Welcome to the final Sprint Challenge of Unit 1!\n",
        "\n",
        "In this challenge, we're going to explore two different datasets where you can demonstrate your skills with fitting linear regression models and practicing some of the linear algebra concepts you learned.\n",
        "\n",
        "**Make sure to follow the instructions in each task carefully!** The autograded tests are very specific in that they are designed to test on the exact instructions.\n",
        "\n",
        "Good luck!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXaq6fq4v5Nl"
      },
      "source": [
        "## Part A: Linear Regression\n",
        "\n",
        "### Use the following information to complete Tasks 1 - 11\n",
        "\n",
        "### Dataset description\n",
        "\n",
        "The data you will work on for this Sprint Challenge is from the World Happiness Report. The report compiles data from a survey of hundreds of countries and looks at factors such as economic production, social support, life expectancy, freedom, absence of corruption, and generosity to determine a happiness \"score\". \n",
        "\n",
        "In this Sprint Challenge, we're only going to look at the report for years 2018 and 2019. We're going to see how much the happiness \"score\" depends on some of the factors listed above.\n",
        "\n",
        "For more information about the data, you can look here: [Kaggle: World Happiness Report](https://www.kaggle.com/unsdsn/world-happiness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9Ht0VS6GiM8"
      },
      "source": [
        "### Task 1 - Load the data\n",
        "\n",
        "* import both `pandas` and `numpy`\n",
        "* use the URL provided to read in your DataFrame\n",
        "* load the CSV file as a DataFrame with the name `happy` and **set the index column as** `Overall_rank`.\n",
        "* the shape of your DataFrame should be `(312, 8)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "3YXv1PZQO5P9",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ca1ff7ab03d2626156c7077279efbc9b",
          "grade": false,
          "grade_id": "cell-eb2386fdd2afedce",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 1\n",
        "\n",
        "# URL provided\n",
        "url = \"https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_1/Happy/happiness_years18_19.csv\"\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print out the DataFrame\n",
        "happy.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llr3FqOkv5Nm"
      },
      "source": [
        "**Task 1 - Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e589a0be1f22eed9621f9f920e9e6ec4",
          "grade": true,
          "grade_id": "cell-3b8176542da639a7",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tBzsjMe-v5Nm"
      },
      "source": [
        "# Task 1 - Test\n",
        "\n",
        "assert isinstance(happy, pd.DataFrame), 'Have you created a DataFrame named `happy`?'\n",
        "assert happy.index.name == 'Overall_rank', \"Your index should be 'Overall_rank'.\"\n",
        "assert len(happy) == 312\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVQcvdcuLgNf"
      },
      "source": [
        "**Task 2** - Explore the data and find NaNs\n",
        "\n",
        "Now you want to take a look at the dataset, determine the variable types of the columns, identify missing values, and generally better understand your data.\n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "* Use describe() and info() to learn about any missing values, the data types, and descriptive statistics for each numeric value\n",
        "* Sum the null values and assign that number to the variable `num_null`; the variable type should be a `numpy.int64` integer.\n",
        "\n",
        "**Hint:** If you use `np.isnull()` it will return the number of null values in each column. You want the total number of null values in the entire DataFrame; one way to do this is to apply the `.sum()` method twice: `.sum().sum()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "Ks9ggzPSSLHv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1aceba5537d63619f7f88992c6e671f6",
          "grade": false,
          "grade_id": "cell-69de35e15b60d456",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 2\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print out your integer result\n",
        "print(\"The total number of null values is:\", num_null)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPJf2ojfv5Nm"
      },
      "source": [
        "**Task 2 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dd46cad66117c2e0527d07d68b97767c",
          "grade": true,
          "grade_id": "cell-bfbfbfc988042998",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gfJBWNU7v5Nn"
      },
      "source": [
        "# Task 2 - Test\n",
        "import numpy as np\n",
        "assert isinstance(num_null, np.int64), 'The sum of the NaN values should be an integer.'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwzN2V5Qv5Nn"
      },
      "source": [
        "**Task 3** - Drop a column\n",
        "\n",
        "As you noticed in the previous task, the column `Perceptions_corruption` has a lot of missing values. Let's determine how many are missing and then drop the column. Note: dropping a column isn't always the best choice when faced with missing values but we're choosing that option here, partly for practice.\n",
        "\n",
        "* Calculate the percentage of NaN values in `Perceptions_corruption` and assign the result to the variable `corruption_nan`; the value should be a **float** between `1.0` and `100.0`.\n",
        "* Drop the `Perceptions_corruption` column from `happy` but keep the DataFrame name the same; use the parameter `inplace=True`. You will also want to specify the axis on which to operate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a93f9d96ac21efaed87c6d3f4bfd1770",
          "grade": false,
          "grade_id": "cell-3d89df738d5913f7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "J3BN9bumv5Nn"
      },
      "source": [
        "# Task 3\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print the percentage of NaN values\n",
        "print(corruption_nan)\n",
        "\n",
        "# Print happy to verify the column was dropped\n",
        "happy.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r_jn5vUv5Nn"
      },
      "source": [
        "***Task 3 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "289ed3c4d169251dba5d450d60e31d53",
          "grade": true,
          "grade_id": "cell-e43da9031a8111f3",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rdwCjhnav5Nn"
      },
      "source": [
        "# Task 3 - Test\n",
        "\n",
        "assert isinstance(corruption_nan, np.float), 'The percentage of NaN values should be a float.'\n",
        "assert corruption_nan >= 1, 'Make sure you calculated the percentage and not the decimal fraction.'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fongqoI9SZje"
      },
      "source": [
        "**Task 4** - Visualize the dataset\n",
        "\n",
        "Next, we'll create a visualization for this dataset. We know from the introduction that we're trying to predict the happiness score from the other factors. Before we do let, let's visualize the dataset using a seaborn `pairplot` to look at all of the columns plotted as \"pairs\".\n",
        "\n",
        "**Your tasks**\n",
        "\n",
        "* Use the seaborn library `sns.pairplot()` function to create your visualization (use the starter code provided)\n",
        "\n",
        "This task will not be autograded - but it is part of completing the challenge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "EvY3PH7sRTLu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c8edd09b4ed4c62a60fecd1f8fe0da87",
          "grade": false,
          "grade_id": "cell-6c94581ca023fcbc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 4\n",
        "# (NOT autograded but fill in your code!)\n",
        "\n",
        "# Import seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# Use sns.pairplot(data) where data is the name of your DataFrame\n",
        "# sns.pairplot()\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-5ZGPmsv5No"
      },
      "source": [
        "**Task 5** - Identify the dependent and independent variables\n",
        "\n",
        "Before we fit a linear regression to the variables in this data set, we need to determine the dependent variable (the target or y variable) and independent variable (the feature or x variable). For this dataset, we have one dependent variable and a few choices for the independent variable(s). Using the information about the data set and what you know from previous tasks, complete the following:\n",
        "\n",
        "* Assign the dependent variable to `y_var`\n",
        "* Choose **one** independent variable and assign it to `x_var`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f27222d4d949b2c537c0b9c6064d5da0",
          "grade": false,
          "grade_id": "cell-9927aa9d9ba87841",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "O_MOy1ZVv5Np"
      },
      "source": [
        "# Task 5\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zCNjINEv5Np"
      },
      "source": [
        "**Task 5 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b958cf71c75a1726572297fcc2c5ce11",
          "grade": true,
          "grade_id": "cell-f28e81084c41c2e2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gTFz6hTrv5Np"
      },
      "source": [
        "# Task 5 - Test\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq-Yh-MQY-k1"
      },
      "source": [
        "**Task 6** - Fit a line using seaborn\n",
        "\n",
        "Before we fit the linear regression model, we'll check how well a line fits. Because you have some choices for which independent variable to select, we're going to complete the rest of our analysis using `GDP per capita` as the independent variable. We're using `Score` as the dependent (target) variable.\n",
        "\n",
        "The seaborn `lmplot()` documentation can be found [here](https://seaborn.pydata.org/generated/seaborn.lmplot.html). You can also use `regplot()` and the documentation is [here](https://seaborn.pydata.org/generated/seaborn.regplot.html)\n",
        "\n",
        "This task will not be autograded - but it is part of completing the challenge!\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "* Create a scatter plot using seaborn with `GDP per capita` and `Score`\n",
        "* Use `sns.lmplot()` or `sns.regplot()` and specify a confidence interval of 0.95\n",
        "* Answer the questions about your plot (not autograded).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "oyCzMaHvalFo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "812a524d7d6c5a129e2d59bdf979d0a3",
          "grade": false,
          "grade_id": "cell-f204f842b9e33871",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 6\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA0PT20JcUFj"
      },
      "source": [
        "**Task 6** - Short answer\n",
        "\n",
        "1. Does it make sense to fit a linear model to these two variables? In otherwords, are there any problems with this data like extreme outliers, non-linearity, etc.\n",
        "2. Over what range of your independent variable does the linear model not fit the data well? Over what range does a line fit the data well?\n",
        "\n",
        "---\n",
        "\n",
        "1. YOUR ANSWER HERE\n",
        "2. YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvPJjQVccfa9"
      },
      "source": [
        "**Task 7** - Fit a linear regression model\n",
        "\n",
        "Now it's time to fit the linear regression model! We have two variables (`GDP_per_capita` and `Score`) that we are going to use in our model.\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "*  Use the provided import for the `statsmodels.formula.api` library `ols` method\n",
        "*  Fit a **single variable linear regression model** and assign the model to the variable `model_1`\n",
        "* Print out the model summary and assign the value of R-squared for this model to `r_square_model_1`. Your value should be defined to three decimal places (example: `r_square_model_1 = 0.123`)\n",
        "* Answer the questions about your resulting model parameters (these short answer questions will not be autograded).\n",
        "\n",
        "**NOTE:** - For this task to be correctly autograded, you need to input the model parameters as specified in the code cell below. Part of this Sprint Challenge is correctly implementing the instructions in each task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "SjxV58yUM-xM",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8e54425ede9366c11df2961ac052ac44",
          "grade": false,
          "grade_id": "cell-10546651c6f95fe8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 7\n",
        "\n",
        "# Import the OLS model from statsmodels\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print the model summary\n",
        "print(model_1.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiAeAvMKv5Nq"
      },
      "source": [
        "**Task 7 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a28499dbbfc37309120f8fc3040a260e",
          "grade": true,
          "grade_id": "cell-3b86656eed5298c4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BQq6_zjDv5Nq"
      },
      "source": [
        "# Task 7 - Test\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSn1C5UWv5Nr"
      },
      "source": [
        "**Task 8** - Interpret your model\n",
        "\n",
        "Using the model summary you printed out above, answer the following questions.\n",
        "\n",
        "* Assign the slope of `GDP_per_capita` to the variable `slope_model_1`; define it to two decimal places (example: 1.23). This variable should be a float.\n",
        "* Assign the p-value for this model parameter to `pval_model_1`; this variable could be either an integer or a float.\n",
        "* Assign the 95% confidence interval to the variables `ci_low` (lower value) and `ci_upper` (upper value); define them to two decimal places.\n",
        "\n",
        "Answer the following questions (not autograded):\n",
        "\n",
        "1. Is the correlation between your variables positive or negative?\n",
        "2. How would you write the confidence interval for your slope coefficient?\n",
        "3. State the null hypothesis to test for a statistically significant relationship between your two variables.\n",
        "4. Using the p-value from your model, do you **reject** or **fail to reject** the null hypothesis?\n",
        "\n",
        "---\n",
        "\n",
        "1. YOUR ANSWER\n",
        "2. YOUR ANSWER\n",
        "3. YOUR ANSWER\n",
        "4. YOUR ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1c831b0d90f740f6e667fb9779292efe",
          "grade": false,
          "grade_id": "cell-ff04e5abbd2537a2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ceWGXREnv5Nr"
      },
      "source": [
        "# Task 8\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPz-Iuslv5Nr"
      },
      "source": [
        "**Task 8 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "302dfb6470104afc8335e76869d87d09",
          "grade": true,
          "grade_id": "cell-77f2fbd53773d189",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xvr5jnNLv5Nr"
      },
      "source": [
        "# Task 8 - Test\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMrxuOaHSFEc"
      },
      "source": [
        "**Task 9** - Fit a multiple predictor linear regression model\n",
        "\n",
        "For this next task, we'll add in an additional independent or predictor variable. Let's look back at the pairplot and choose another variable - we'll use `Social_support`. Recall from the Guided Projects and Module Projects that we are looking to see if adding the variable `Social_support` is statistically significant after accounting for the `GDP_per_capita` variable.\n",
        "\n",
        "We're going to fit a linear regression model using two predictor variables: `GDP_per_capita` and `Social_support`.\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "* Fit a model with both predictor variables and assign the model to `model_2`. The format of the input to the model is `Y ~ X1 + X2`. \n",
        "    * **X1 = `GDP_per_capita`** and  **X2 = `Social_support`**.\n",
        "* Print out the model summary and assign the value of R-squared for this model to `r_square_model_2`. Your value should be defined to three decimal places.\n",
        "* Assign the value of the adjusted R-square to `adj_r_square_model_2`. Your value should be defined to three decimal places.\n",
        "* Answer the questions about your resulting model parameters (these short answer questions will not be autograded)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6e498ec0b9abb6bce1904ff83f7bfe35",
          "grade": false,
          "grade_id": "cell-1a29f6750fdbe94d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "c5sRddXEv5Nr"
      },
      "source": [
        "# Task 9\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print the model summary\n",
        "print(model_2.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e-R27Qmv5Nr"
      },
      "source": [
        "**Task 9 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Nu3XGDFqb8RT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9b0df6ed4c92cd8eafa6b20d8ed44156",
          "grade": true,
          "grade_id": "cell-6846d1802647bc27",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Task 9 - Test\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH4LRUiCv5Ns"
      },
      "source": [
        "**Task 10** - Multiple regression model interpretation\n",
        "\n",
        "Now that we have added an additional variable to our regression model, let's look at how the explained variance (the R-squared value) changes.\n",
        "\n",
        "**Your tasks**\n",
        "* Find the explained variance from `model_1` and assign it to the variable `r_square_percent1`; your variable should be expressed as a **percentage** and should be rounded to the nearest integer.\n",
        "* Find the explained variance (*adjusted!*) from `model_2` and assign it to the variable `r_square_adj_percent2`; you variable should be expressed as a **percentage** and should be rounded to the nearest integer.\n",
        "\n",
        "---\n",
        "Question (not autograded):\n",
        "\n",
        "How does the adjusted R-squared value change when a second predictor variable is added?\n",
        "\n",
        "YOUR ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ef4696f34cb40872f55641a6f8feca12",
          "grade": false,
          "grade_id": "cell-7cfd2ed27e73447c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "jTnmabTSv5Ns"
      },
      "source": [
        "# Task 10\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK8hRDEWv5Ns"
      },
      "source": [
        "**Task 10 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "85e98df5198dd82b2f294959e43df53a",
          "grade": true,
          "grade_id": "cell-5e3a43399fcea221",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "klQcMa2ev5Ns"
      },
      "source": [
        "# Task 10 - Test\n",
        "assert r_square_percent1 >= 1, 'Make sure you use the percentage and not the decimal fraction.'\n",
        "assert r_square_adj_percent2 >= 1, 'Make sure you use the percentage and not the decimal fraction.'\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA3XVQvJv5Ns"
      },
      "source": [
        "**Task 11** - Making a prediction and calculating the residual\n",
        "\n",
        "We're going to use our model to make a prediction. Refer to the `happy` DataFrame and find the `GDP_per_capita` score for \"Iceland\" (index 4).  Then when we have a prediction, we can calculate the residual.\n",
        "\n",
        "**Prediction**\n",
        "* Assign the `GDP_per_capita` value to the variable `x_iceland`; it should be float and defined out to two decimal places.\n",
        "* Using your slope and intercept values from `model_1`, calculate the `Score` for Iceland (`x_iceland`); assign this value to `predict_iceland` and it should be a float.\n",
        "\n",
        "**Residual**\n",
        "* Assign the observed `Score` for Iceland and assign it to the variable `observe_iceland`; it should be float and defined out to two decimal places *(careful with the rounding!)*.\n",
        "* Determine the residual for the prediction you made and assign it to the variable `residual_iceland` (use your Guided Project or Module Project notebooks if you need a reminder of how to do a residual calculation).\n",
        "\n",
        "Hint: Define your slope and intercept values out to two decimal places! Your resulting prediction for Iceland should have at least two decimal places. **Make sure to use the parameters from the first model (`model_1`)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a203aa95f1748959b0f81c97049f838a",
          "grade": false,
          "grade_id": "cell-6207377c22d4f665",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mnGwTR_Rv5Ns"
      },
      "source": [
        "# Task 11\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# View your prediction\n",
        "print('Prediction for Iceland :', predict_iceland)\n",
        "print('Residual for Iceland prediction :', residual_iceland)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFJJUfxxv5Nt"
      },
      "source": [
        "**Task 11 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8cf47aea3620dd0fa2f9191e8c36bab0",
          "grade": true,
          "grade_id": "cell-43679cadf6a7910a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2rrX42PTv5Nt"
      },
      "source": [
        "# Task 11 - Test\n",
        "\n",
        "assert residual_iceland >= 0, 'Check your residual calculation (use observed - predicted).'\n",
        "assert round(x_iceland, 1) == 1.3, 'Check your Iceland GDP value.'\n",
        "assert round(observe_iceland, 1) == 7.5, 'Check your Iceland observation value for \"Score\".'\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfZxg7Xof5dj"
      },
      "source": [
        "## Part B: Vectors and cosine similarity\n",
        "\n",
        "In this part of the challenge, we're going to look at how similar two vectors are. Remember, we can calculate the **cosine similarity** between two vectors by using this equation:\n",
        "\n",
        "$$\\cos \\theta= \\frac{\\mathbf {A} \\cdot \\mathbf {B} }{\\left\\|\\mathbf {A} \\right\\|\\left\\|\\mathbf {B} \\right\\|}$$\n",
        "\n",
        "$\\qquad$\n",
        "\n",
        "where\n",
        "\n",
        "* The numerator is the dot product of the vectors $\\mathbf {A}$ and $\\mathbf {B}$\n",
        "* The denominator is the norm of $\\mathbf {A}$ times the norm of $\\mathbf {B}$\n",
        "\n",
        "### Three documents, two authors\n",
        "\n",
        "For this task, you will calculate the cosine similarity between three vectors. But here's the interesting part: each vector represents a \"chunk\" of text from a novel (a few chapters of text). This text was cleaned to remove non-alphanumeric characters and numbers and then each document was transformed into a vector representation as described below.\n",
        "\n",
        "### Document vectors\n",
        "\n",
        "In the dataset you are going to load below, each row represents a word that occurs in at least one of the documents. So all the rows are all the words that are in our three documents.\n",
        "\n",
        "Each column represents a document (doc0, doc1, doc2). Now the fun part: the value in each cell is how frequently that word (row) occurs in that document (term-frequency) divided by how many documents that words appears in (document-frequency).\n",
        "\n",
        "`cell value = term_frequency / document_frequency`\n",
        "\n",
        "Use the above information to complete the remaining tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW9DtZNwv5Nt"
      },
      "source": [
        "**Task 12** - Explore the text documents\n",
        "\n",
        "You will be using cosine similarity to compare each document vector to the others. Remember that there are three documents, but two authors. Your task is to use the cosine similarity calculations to determine which two document vectors are most similar (written by the same author).\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "* Load in the CSV file that contains the document vectors (this is coded for you - just run the cell)\n",
        "* Look at the DataFrame you just loaded in any way that helps you understand the format, what's included in the data, the shape of the DataFrame, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHcKj5epb8UQ"
      },
      "source": [
        "# Imports (import pandas if you haven't yet)\n",
        "\n",
        "# Load the data - DON'T DELETE THIS CELL\n",
        "url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/text_vectors.csv'\n",
        "text = pd.read_csv(url)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6orkQNkvyleB"
      },
      "source": [
        "# Task 12\n",
        "\n",
        "## Explore the data\n",
        "\n",
        "# (this part is not autograded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s78gaNeEv5Nt"
      },
      "source": [
        "**Task 13** - Calculate cosine similarity\n",
        "\n",
        "* Calculate the cosine similarity for **three pairs of vectors** and assign the results to the following variables (each variable will be a float):\n",
        "\n",
        "  * assign the cosine similarity of doc0-doc1 to `cosine_doc0_1`\n",
        "  * assign the cosine similarity of doc0-doc2 to `cosine_doc0_2`\n",
        "  * assign the cosine similarity of doc1-doc2 to `cosine_doc1_2`\n",
        "\n",
        "* Print out the results so you can refer to them for the short answer section.\n",
        "* Answer the questions after you have completed the cosine similarity calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "AgTYYDTbzDnd",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "330a8012f7fec0c9efd836931f5e9693",
          "grade": false,
          "grade_id": "cell-930c2a345a43f4dc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Task 13\n",
        "\n",
        "# Use these imports for you cosine calculations (DON'T DELETE)\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# Print out the results\n",
        "print('Cosine similarity for doc0-doc1:', cosine_doc0_1)\n",
        "print('Cosine similarity for doc0-doc2:', cosine_doc0_2)\n",
        "print('Cosine similarity for doc1-doc2:', cosine_doc1_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eS4D8WD0_xe"
      },
      "source": [
        "**Task 13** - Short answer\n",
        "\n",
        "1. Using your cosine similarity calculations, which two documents are most similar?\n",
        "2. If doc1 and doc2 were written by the same author, are your cosine similarity calculations consistent with this statement?\n",
        "3. What process would we need to follow to add an additional document column? In other words, why can't we just stick another column with (term-frequency/document-frequency) values onto our current DataFrame `text`?\n",
        "\n",
        "---\n",
        "\n",
        "1. YOUR ANSWER\n",
        "2. YOUR ANSWER\n",
        "3. YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww9e9RCIv5Nu"
      },
      "source": [
        "**Task 13 Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e85d26812acfc6927a7a53d559ee5060",
          "grade": true,
          "grade_id": "cell-67070a6545eede1c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cQzWnGn3v5Nu"
      },
      "source": [
        "# Task 13 - Test\n",
        "\n",
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Foxa3p2an1"
      },
      "source": [
        "**Additional Information about the texts used in this analysis:**\n",
        "\n",
        "You can find the raw text [here](https://github.com/LambdaSchool/data-science-practice-datasets/tree/main/unit_4/unit1_nlp). Dcoument 0 (doc0) is chapters 1-3 from \"Pride and Predjudice\" by Jane Austen. Document 1 (doc1) is chapters 1- 4 from \"Frankenstein\" by Mary Shelley. Document 2 is also from \"Frankenstein\", chapters 11-14."
      ]
    }
  ]
}